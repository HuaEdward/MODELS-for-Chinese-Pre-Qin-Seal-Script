# Pre-Qin Seal-Script Region Classifier (Training+Inference) â€” å…ˆç§¦ç¯†æ›¸åœ‹åˆ¥åˆ†é¡å™¨ï¼ˆè¨“ç·´ï¼‹æ¨ç†ï¼‰

ç›®å‰è¨“ç·´æ•¸æ“šé›†ä¸¦ä¸å®Œå‚™ï¼ˆç‰¹åˆ¥æ˜¯ç‡•åœ‹æ–‡å­—ï¼‰ï¼Œæœ¬äººåªæ˜¯é«˜ä¸­ç”Ÿï¼Œå¸Œæœ›æ›´å¤šåŒé“èƒ½æä¾›ä¸€äº›å¹«åŠ©ï¼
The current training dataset is incomplete (especially the Yan script). I am only a high school student and hope that more ancient script researchers can provide some help!

> ç¹é«”ä¸­æ–‡ / English


## ç°¡ä»‹ (Overview)

æ­¤å°ˆæ¡ˆç”¨æ–¼åˆ¤æ–·**å…ˆç§¦ç¯†æ›¸**ï¼ˆå–®å­—æˆ–æ•´æ®µç¢‘æ–‡ï¼‰æ›´å¯èƒ½å±¬æ–¼ **ç§¦ / é½Š / ç‡• / æ¥š / ä¸‰æ™‰** ä¹‹å“ªä¸€æ–¹åœ‹åˆ¥ã€‚  
- **å–®å­—å±¤ç´š**ï¼šè¼¸å…¥å–®å­—å½±åƒï¼Œè¼¸å‡ºäº”åœ‹æ©Ÿç‡èˆ‡å¯è¦–åŒ–åœ–ã€‚:contentReference[oaicite:0]{index=0}  
- **ç¢‘æ–‡å±¤ç´š**ï¼šè¼¸å…¥ä¸€å€‹è³‡æ–™å¤¾ï¼ˆå«å¤šå¼µå–®å­—åœ–ï¼‰ï¼Œå°å…¶**æ•´é«”**åšåœ‹åˆ¥æ­¸å±¬æ¨æ–·ï¼Œä¸¦è¼¸å‡ºç¸½è¡¨èˆ‡åœ–è¡¨ã€‚:contentReference[oaicite:1]{index=1}  
- äº¦æä¾›è³‡æ–™å‰è™•ç†è…³æœ¬ï¼Œå°‡åŸåœ–è¦ä¸€åŒ–ç‚º**é»‘åº•ç™½å­—ã€ç­‰æ¯”ç½®ä¸­**ä¹‹è¨“ç·´è¼¸å…¥ã€‚:contentReference[oaicite:2]{index=2}

This project classifies **Pre-Qin seal-script** (single characters or whole inscriptions) into one of **Qin / Qi / Yan / Chu / SanJin**.  
- **Single character**: image â†’ probabilities over 5 states + visualization. :contentReference[oaicite:3]{index=3}  
- **Whole inscription**: a folder of characters â†’ overall attribution + CSV and plots. :contentReference[oaicite:4]{index=4}  
- Includes preprocessing to normalize images to **white on black, centered, fixed size**. :contentReference[oaicite:5]{index=5}

---

## å°ˆæ¡ˆçµæ§‹ (Project Structure)

```

.
â”œâ”€â”€ data/                          # è¨“ç·´è³‡æ–™ï¼ˆæŒ‰åœ‹åˆ¥åˆ†å­è³‡æ–™å¤¾ï¼‰
â”‚   â”œâ”€â”€ Qin/
â”‚   â”‚   â”œâ”€â”€ input\_images/          # åŸå§‹åœ–
â”‚   â”‚   â””â”€â”€ output\_images/         # å‰è™•ç†å¾Œåœ–ï¼ˆç”¨æ–¼è¨“ç·´ï¼‰
â”‚   â”œâ”€â”€ Qi/  ...ï¼ˆYan / Chu / SanJin åŒçµæ§‹ï¼‰
â”‚
â”œâ”€â”€ single\_character\_prediction/    # å–®å­—æ‰¹æ¬¡æ¨ç†è¼¸å…¥/è¼¸å‡º
â”‚   â”œâ”€â”€ input/
â”‚   â””â”€â”€ output/
â”œâ”€â”€ inscription\_prediction/         # ç¢‘æ–‡ï¼ˆæ•´æ®µï¼‰æ¨ç†è¼¸å…¥/è¼¸å‡º
â”‚   â”œâ”€â”€ input/
â”‚   â””â”€â”€ output/
â”‚
â”œâ”€â”€ data\_prep.py                    # å‰è™•ç†ï¼šç°éšâ†’äºŒå€¼â†’ç™½å­—é»‘åº•â†’ç­‰æ¯”ç½®ä¸­ 128Ã—128 &#x20;
â”œâ”€â”€ train\_model.py                  # è¨“ç·´è…³æœ¬ï¼ˆå®šç¾© AncientTextClassifierï¼‰
â”œâ”€â”€ single\_character\_predict.py     # å–®å­—æ¨ç†ï¼ˆç¹ªè£½æ©Ÿç‡é•·æ¢åœ–ã€è¼¸å‡º CSVï¼‰    &#x20;
â”œâ”€â”€ inscription\_predict.py          # ç¢‘æ–‡æ¨ç†ï¼ˆæ•´é«”æ©Ÿç‡ï¼å¤šå­—å¹³å‡+æ­£è¦åŒ–ï¼‰    &#x20;
â”œâ”€â”€ ancient\_text\_classifier.pth     # è¨“ç·´å¾Œæ¨¡å‹ï¼ˆæˆ– best\_model.pthï¼‰
â”œâ”€â”€ model\_info.json                 # æ¨¡å‹èˆ‡è¨“ç·´é…ç½®
â”œâ”€â”€ training\_history.png            # è¨“ç·´éç¨‹æ›²ç·š
â””â”€â”€ requirements.txt

````

---

## å®‰è£éœ€æ±‚ (Requirements)

- Python 3.9+
- ä¸»è¦å¥—ä»¶ï¼š`opencv-python`, `numpy`, `pandas`, `matplotlib`, `torch`, `torchvision`
- å»ºè­°ä½¿ç”¨ GPU çš„ PyTorch ç‰ˆæœ¬ä»¥åŠ é€Ÿæ¨ç†

**English:**  
- Python 3.9+  
- Core packages: `opencv-python`, `numpy`, `pandas`, `matplotlib`, `torch`, `torchvision`  
- GPU-enabled PyTorch is recommended for faster inference

Install:
```bash
pip install -r requirements.txt
````

---

## è³‡æ–™å‰è™•ç† (Data Preprocessing)

**ç›®çš„**ï¼šå°‡ä»»æ„åº•è‰²/å¤§å°çš„å­—å½¢å½±åƒï¼Œè½‰ç‚º**ç™½å­—é»‘åº•**ã€ç¶­æŒæ¯”ä¾‹ã€ç½®ä¸­åˆ° **128Ã—128**ï¼Œä¸¦è¼¸å‡ºåˆ°å„åœ‹åˆ¥çš„ `output_images/`ã€‚
**ç”¨æ³•**ï¼š

```bash
python data_prep.py
```

* ç¨‹å¼æœƒéæ­· `data/<State>/input_images/`ï¼Œè¼¸å‡ºåˆ° `data/<State>/output_images/`ã€‚
* å‰è™•ç†åŒ…å«ï¼šç°éšè®€å– â†’ äºŒå€¼åŒ– â†’ å¿…è¦æ™‚åç›¸ï¼ˆçµ±ä¸€ç™½å­—é»‘åº•ï¼‰ â†’ ç­‰æ¯”ç¸®æ”¾èˆ‡ç½®ä¸­ã€‚

**English:**

* **Goal:** Normalize any input glyph to **white-on-black**, aspect-preserved, centered **128Ã—128** canvases, and write to each stateâ€™s `output_images/`.
* **Usage:** `python data_prep.py`
* The script scans `data/<State>/input_images/` and saves to `data/<State>/output_images/`.
* Steps: grayscale â†’ binarize â†’ invert if needed (unify white-on-black) â†’ scale with aspect ratio and center.

This script walks through `data/<State>/input_images/` and writes normalized images to `.../output_images/`, standardizing to 128Ã—128 white-on-black, centered canvases.&#x20;

---

## è¨“ç·´ (Training)

```bash
python train_model.py
```

è¼¸å‡ºå°‡åŒ…å«ï¼š

* `ancient_text_classifier.pth`ï¼ˆæˆ– `best_model.pth`ï¼‰
* `model_info.json`
* `training_history.png`

> è‹¥ä½ å·²æä¾›è¨“ç·´å®Œæˆçš„ `*.pth`ï¼Œå¯ç›´æ¥é€²å…¥ã€Œæ¨ç†ã€æ­¥é©Ÿã€‚

**English:**
Running `python train_model.py` produces:

* `ancient_text_classifier.pth` (or `best_model.pth`)
* `model_info.json`
* `training_history.png`

> If you already have a trained `*.pth`, you can skip training and go straight to inference.

---

## å–®å­—æ¨ç† (Single-Character Inference)

### äº’å‹•æ¨¡å¼ï¼ˆCLIï¼‰

```bash
python single_character_predict.py
```

åŠŸèƒ½é¸å–®åŒ…å«ï¼š

1. å–®å¼µåœ–ç‰‡é æ¸¬ â†’ é¡¯ç¤ºäº”åœ‹æ©Ÿç‡ã€ç”Ÿæˆå°æ‡‰åœ–è¡¨èˆ‡è™•ç†å¾Œå½±åƒ
2. æ‰¹æ¬¡é æ¸¬ `single_character_prediction/input/` â†’ è¼¸å‡ºåˆ° `.../output/`
3. æª¢è¦– I/O è³‡æ–™å¤¾ç‹€æ…‹
   ï¼ˆæµç¨‹èˆ‡è¼¸å‡ºæª”åï¼šè¦‹ç¨‹å¼å…§ `predict_batch()` èˆ‡ `create_result_visualization()`ï¼Œå«åœ–è¡¨èˆ‡ CSV åŒ¯å‡ºã€‚ï¼‰

**English:**
Interactive menu:

1. Predict a single image â†’ show probabilities for all regions and save chart + processed glyph
2. Batch predict images under `single_character_prediction/input/` â†’ outputs to `.../output/`
3. Inspect I/O folders (details and filenames implemented in `predict_batch()` and `create_result_visualization()`; charts and CSV are exported)

**æ‰¹æ¬¡æ¨ç†ç›´æ¥ç”¨æ³•**ï¼š

```bash
python -c "from single_character_predict import Predictor; Predictor().predict_batch('single_character_prediction/input','single_character_prediction/output')"
```

* å¯è¦–åŒ–åœ–ï¼š`*_result.png`
* å‰è™•ç†å½±åƒï¼š`*_processed.png`
* æ˜ç´° CSVï¼š`prediction_results_YYYYMMDD_HHMMSS.csv`ï¼ˆå«å„åœ‹æ©Ÿç‡èˆ‡ Top1ï¼‰

**English:**

* Visualization: `*_result.png`
* Preprocessed glyph: `*_processed.png`
* Detailed CSV: `prediction_results_YYYYMMDD_HHMMSS.csv` (includes per-region probabilities and Top-1)

The `Predictor` loads `ancient_text_classifier.pth` or `best_model.pth`, runs the same preprocessing as training (white-on-black 128Ã—128), and exports charts + CSV.&#x20;

---

## ç¢‘æ–‡ï¼ˆæ•´æ®µï¼‰æ¨ç† (Whole-Inscription Inference)

å°‡åŒä¸€æ®µç¢‘æ–‡çš„**æ‰€æœ‰å–®å­—åœ–**æ”¾åœ¨ä¸€å€‹å­è³‡æ–™å¤¾ï¼Œä¾‹å¦‚ï¼š

```
inscription_prediction/
â””â”€ input/
   â”œâ”€ stele_A/
   â”‚  â”œâ”€ 001.png
   â”‚  â”œâ”€ 002.png
   â”‚  â””â”€ ...
   â””â”€ stele_B/
      â””â”€ ...
```

åŸ·è¡Œï¼š

```bash
python inscription_predict.py
```

æ¯å€‹ç¢‘æ–‡è³‡æ–™å¤¾æœƒå¾—åˆ°ï¼š

* **æ•´é«”æ©Ÿç‡åœ–**ï¼š`input_overall_prediction.png`
* **é€å­—æ˜ç´°è¡¨**ï¼š`input_detailed_predictions.csv`ï¼ˆæ¯å¼µå–®å­—åœ–çš„äº”åœ‹æ©Ÿç‡ï¼‰
* è«‹è¦‹ `InscriptionPredictor.predict_inscription()`ï¼šå°æ‰€æœ‰å–®å­—çš„æ©Ÿç‡å–å¹³å‡ï¼Œå†æ­£è¦åŒ–ç‚ºç™¾åˆ†æ¯”ä½œç‚ºæ•´æ®µé æ¸¬ã€‚

**English:**
Place all single-character crops of one inscription in a subfolder under `inscription_prediction/input/`, then run `python inscription_predict.py`.
For each inscription youâ€™ll get:

* `input_overall_prediction.png` â€” overall regional probabilities
* `input_detailed_predictions.csv` â€” per-character probabilities
* Implementation detail: `InscriptionPredictor.predict_inscription()` averages per-character probabilities and normalizes to percentages.

---

## I/O èˆ‡è¼¸å‡ºæ ¼å¼ (I/O & Outputs)

* **æ”¯æ´å½±åƒæ ¼å¼**ï¼šPNG / JPG / JPEG / BMP / TIFFï¼ˆå–®å­—åœ–å³å¯ï¼‰
* **å–®å­—è¼¸å‡º**ï¼ˆsingle\_character\_prediction/outputï¼‰ï¼š

  * `*_result.png`ï¼šå·¦å´é¡¯ç¤ºé è™•ç†å½±åƒï¼Œå³å´ç‚ºäº”åœ‹æ©Ÿç‡é•·æ¢åœ–
  * `*_processed.png`ï¼š128Ã—128 è¦ä¸€åŒ–å½±åƒ
  * `prediction_results_*.csv`ï¼šæ¯å¼µåœ–çš„ Top1 èˆ‡å„åœ‹æ©Ÿç‡ï¼ˆ%ï¼‰
* **ç¢‘æ–‡è¼¸å‡º**ï¼ˆinscription\_prediction/output/<inscription>/ï¼‰ï¼š

  * `input_overall_prediction.png`ï¼šæ•´æ®µå¹³å‡å¾Œçš„åœ‹åˆ¥æ©Ÿç‡ï¼ˆ%ï¼‰
  * `input_detailed_predictions.csv`ï¼šé€å­—æ©Ÿç‡æ˜ç´°è¡¨ï¼ˆåŒè³‡æ–™å¤¾å…§å…¨éƒ¨å–®å­—ï¼‰

**English:**

* **Supported formats:** PNG / JPG / JPEG / BMP / TIFF
* **Single-character outputs** (`single_character_prediction/output`):

  * `*_result.png` (processed glyph on the left; bar chart of regional probabilities on the right)
  * `*_processed.png` (normalized 128Ã—128 glyph)
  * `prediction_results_*.csv` (Top-1 and all region probabilities)
* **Inscription outputs** (`inscription_prediction/output/<inscription>/`):

  * `input_overall_prediction.png` (overall regional percentages)
  * `input_detailed_predictions.csv` (per-glyph probability table)

---

## å¸¸è¦‹å•é¡Œ (FAQ)

**Q1. åœ–ç‰‡è¦æ€éº¼æº–å‚™ï¼Ÿ**
ç›¡é‡è£åˆ°**å–®å­—**ï¼ŒèƒŒæ™¯ç°¡æ½”ã€‚è‹¥ä¸ç¢ºå®šï¼Œå¯å…ˆæ”¾åˆ° `data/<State>/input_images/`ï¼Œè·‘ä¸€æ¬¡ `data_prep.py` çœ‹è¦ä¸€åŒ–æ•ˆæœã€‚

**English:**
**Q1. How should I prepare images?**
Crop to **single characters** with clean backgrounds. If unsure, place them in `data/<State>/input_images/` and run `data_prep.py` to preview normalization.

**Q2. æ¨ç†çµæœç‚ºä½•æ˜¯ç™¾åˆ†æ¯”ä¸”ç¸½å’Œè¿‘ 100%ï¼Ÿ**
åˆ†é¡è¼¸å‡ºç¶“ softmax è½‰ç‚ºç™¾åˆ†æ¯”ã€‚å–®å­—èˆ‡ç¢‘æ–‡æ¨¡å¼çš†è¼¸å‡ºäº”åœ‹ç™¾åˆ†æ¯”ï¼›ç¢‘æ–‡æ¨¡å¼å°å¤šå¼µå–®å­—å–å¹³å‡å¾Œå†æ­£è¦åŒ–ã€‚

**English:**
**Q2. Why percentages summing to \~100%?**
Outputs are softmax probabilities. Both single-character and inscription modes report regional percentages; inscription mode averages per-glyph results then normalizes.

**Q3. æ‰¹æ¬¡æ¨ç†èˆ‡äº’å‹•å¼æœ‰ä½•å·®åˆ¥ï¼Ÿ**
äº’å‹•å¼æœƒè©¢å•æ“ä½œä¸¦é¡¯ç¤ºå³æ™‚çµæœï¼›æ‰¹æ¬¡æ¨¡å¼ç›´æ¥æƒææŒ‡å®šè³‡æ–™å¤¾ä¸¦åŒ¯å‡ºåœ–è¡¨èˆ‡ CSVï¼Œä¾¿æ–¼å¤§é‡è™•ç†ã€‚

**English:**
**Q3. Difference between batch and interactive?**
Interactive prompts for actions and displays immediate results; batch scans a folder and exports charts + CSV for large-scale processing.

**Q4. æ¨¡å‹æª”æ¡ˆæ‰¾ä¸åˆ°ï¼Ÿ**
ç¢ºä¿æ ¹ç›®éŒ„ä¸‹å­˜åœ¨ `ancient_text_classifier.pth` æˆ– `best_model.pth`ï¼›å¦å‰‡å…ˆåŸ·è¡Œ `train_model.py` è¨“ç·´ã€‚

**English:**
**Q4. Model file not found?**
Ensure `ancient_text_classifier.pth` or `best_model.pth` exists in the project root, or run `train_model.py` first.

---

## å¼•ç”¨èˆ‡å‚™è¨» (Notes)

* æœ¬å°ˆæ¡ˆä¹‹ç¨‹å¼æµç¨‹èˆ‡ I/O ä»‹é¢ä»¥ä¸‰æ”¯æ ¸å¿ƒè…³æœ¬ç‚ºæº–ï¼š
  `data_prep.py`ï¼ˆå‰è™•ç†ï¼‰ã€`single_character_predict.py`ï¼ˆå–®å­—æ¨ç†ï¼‰ã€`inscription_predict.py`ï¼ˆç¢‘æ–‡æ¨ç†ï¼‰ã€‚
  å…§å«ä¹‹ç´°ç¯€ï¼ˆä¾‹å¦‚è¦ä¸€åŒ–æ–¹å¼ã€è¼¸å‡ºæª”åã€å¹³å‡ç­–ç•¥ï¼‰å¯æ–¼ç¨‹å¼ç¢¼ä¸­æŸ¥é–±ã€‚

**English:**
This projectâ€™s pipeline and I/O are defined by three core scripts:
`data_prep.py` (preprocessing), `single_character_predict.py` (single-character inference), and `inscription_predict.py` (inscription inference).
See code for details such as normalization, filenames, and averaging strategies.

---

## æˆæ¬Šèˆ‡è‡´è¬ (License & Acknowledgements)

* åƒ…ä¾›ç ”ç©¶èˆ‡å€‹äººä½¿ç”¨ã€‚è³‡æ–™èˆ‡å­—é«”ä¹‹æˆæ¬Šä»¥å…¶åŸå§‹æˆæ¬Šç‚ºæº–ã€‚

* è‹¥ä½ é¡˜æ„åˆ†äº«è³‡æ–™æˆ–æ”¹é€²æ¨¡å‹ï¼Œéå¸¸æ„Ÿè¬ä½ çš„å¹«å¿™ï¼ï¼ˆç‰¹åˆ¥æ˜¯è£œå……ç‡•åœ‹ç¯†æ›¸å­—ä¾‹ ğŸ™ï¼‰

**English:**

* For research and personal use only. Dataset/font licenses follow their original terms.
* Contributions of data and model improvements are warmly welcomedâ€”especially additional **Yan** exemplars ğŸ™
